{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../Module')\n",
    "folder_path = '../Dataset'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import set_config\n",
    "\n",
    "from loader_csv import charger_csv\n",
    "from data_to_csv import df_to_csv\n",
    "from utils import generate_description\n",
    "from currency import currency_cleaning\n",
    "from naics_engineering import naicsEngineering\n",
    "\n",
    "df = pd.read_csv(folder_path + '/SBA_Cleaned_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Approve']\n",
    "X = df.drop('Approve', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.05, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_selector = X.select_dtypes(exclude='object').columns\n",
    "categorical_columns_selector = X.select_dtypes(include='object').columns\n",
    "\n",
    "numerical_columns = X[numerical_columns_selector]\n",
    "categorical_columns = X[categorical_columns_selector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  \n",
    "    ('scaler', StandardScaler())  \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns_selector),\n",
    "        ('cat', categorical_transformer, categorical_columns_selector)\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('gbm', GradientBoostingClassifier())  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'gbm__n_estimators': [100],  \n",
    "    'gbm__learning_rate': [0.05, 0.1, 0.2],  \n",
    "    'gbm__max_depth': [5],\n",
    "    'gbm__subsample': [0.7, 1.0],\n",
    "    'gbm__max_features': [None, 'sqrt', 'log2'],\n",
    "    'gbm__loss': ['deviance', 'exponential'],\n",
    "    'gbm__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "    'gbm__init': ['zero', 'random'],\n",
    "    'gbm__random_state': [42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs hyperparamètres trouvés :\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleure précision trouvée :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = f1_score(y_test, predictions, average='macro')\n",
    "print(\"F1-score macro sur l'ensemble de test :\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'learning_rate': [0.05, 0.1, 0.2],\n",
    "#     'max_depth': [3, 4, 5],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'subsample': [0.8, 0.9, 1.0],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'loss': ['deviance', 'exponential'],\n",
    "#     'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "#     'min_impurity_decrease': [0.0, 0.1, 0.2],\n",
    "#     'min_impurity_split': [None, 0.1, 0.2],\n",
    "#     'init': ['zero', 'random'],\n",
    "#     'random_state': [42], \n",
    "#     'n_jobs': [-1]  \n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
